# ğŸ¤– LLM-Based Evaluation for Turkish Banking

## The Problem We Solved

### **Issue: Substring Matching Fails for Turkish**

The original evaluation used **simple substring matching** (`communicate_info`):
```python
if "Agent should clearly communicate" in message.content.lower():
    # âŒ This fails because agent responds in Turkish!
```

**Result**: Agent performs perfectly but gets 0 reward because:
- Agent says: "HesabÄ±nÄ±zÄ±n gÃ¼ncel bakiyesi: 2.500 TL" (Turkish)
- Evaluation looks for: "account balance" (English)
- âŒ No match â†’ 0 reward

### **Solution: LLM-as-a-Judge** âœ…

We switched to **NL Assertions** which uses an LLM to evaluate:
```python
# LLM evaluates if agent met the expectation, regardless of language
nl_assertion = "Agent should provide clear account balance information"
# âœ… LLM understands that Turkish response meets this criterion!
```

---

## What Changed

### **Before (Substring Matching):**
```json
{
    "evaluation_criteria": {
        "communicate_info": [
            "Agent should clearly communicate the current account balance",
            "Agent should explain recent transactions"
        ],
        "reward_basis": ["DB", "COMMUNICATE"]
    }
}
```

**How it evaluates:**
```python
# Simple string search
if "account balance" in agent_message.lower():
    âœ… Pass
else:
    âŒ Fail  # <-- Fails for Turkish!
```

### **After (LLM-Based Evaluation):**
```json
{
    "evaluation_criteria": {
        "nl_assertions": [
            "Agent should verify Turkish customer identity using TC Kimlik No",
            "Agent should provide clear account balance information in Turkish Lira",
            "Agent should explain recent Turkish banking transactions"
        ],
        "reward_basis": ["DB", "NL_ASSERTION"]
    }
}
```

**How it evaluates:**
```python
# LLM reads the conversation and evaluates semantically
llm_prompt = """
Did the agent verify customer identity using TC Kimlik No?
Did the agent provide clear account balance information?
"""
# âœ… LLM understands Turkish and semantic meaning!
```

---

## Benefits of LLM Evaluation

### **1. Language Agnostic** ğŸŒ
- âœ… Works with Turkish responses
- âœ… Works with any language
- âœ… No need for translation

### **2. Semantic Understanding** ğŸ§ 
- âœ… Understands paraphrasing
- âœ… Recognizes equivalent information
- âœ… Evaluates intent, not exact words

### **3. Robust** ğŸ’ª
- âœ… Handles different phrasings
- âœ… Handles formatting variations
- âœ… More realistic evaluation

### **4. Flexible** ğŸ¯
- âœ… Can evaluate complex criteria
- âœ… Can check multiple aspects
- âœ… Provides reasoning for decisions

---

## Example: Real Simulation

### **Agent Response (Turkish):**
```
"Kimlik doÄŸrulamanÄ±z baÅŸarÄ±yla tamamlandÄ± AyÅŸe HanÄ±m.

HesabÄ±nÄ±zÄ±n gÃ¼ncel bakiyesi: 2.500 TL'dir.

Son iÅŸlemlerinizden bazÄ±larÄ±:
1. 10 Ocak 2025 â€“ 500 TL yatÄ±rma (maaÅŸ yatÄ±rÄ±mÄ±) â€“ tamamlandÄ±
2. 9 Ocak 2025 â€“ 100 TL Ã§ekme â€“ tamamlandÄ±"
```

### **Evaluation with Substring Matching:**
```
Looking for: "account balance"
In message: "HesabÄ±nÄ±zÄ±n gÃ¼ncel bakiyesi: 2.500 TL'dir"
âŒ FAIL - "account balance" not found!
```

### **Evaluation with LLM-as-a-Judge:**
```
NL Assertion: "Agent should provide clear account balance information in Turkish Lira"
LLM Analysis: "The agent clearly states 'HesabÄ±nÄ±zÄ±n gÃ¼ncel bakiyesi: 2.500 TL'
               which is the account balance in Turkish Lira."
âœ… PASS - Criterion met!
```

---

## How to Run with NL Assertions

### **Default Evaluation (uses reward_basis from task):**
```bash
tau2 run --domain banking --task-ids banking_001
```

This will now use **NL_ASSERTION** evaluation because we set:
```json
"reward_basis": ["DB", "NL_ASSERTION"]
```

### **Force Specific Evaluation Type:**
```bash
# Use only NL assertions
tau2 run --domain banking --evaluation-type nl_assertions

# Use all evaluations including NL assertions
tau2 run --domain banking --evaluation-type all_with_nl_assertions
```

---

## NL Assertions in Turkish Banking

### **Our NL Assertions Check:**

#### **Banking Task 001 (Balance Inquiry)**
```json
[
    "Agent should verify Turkish customer identity using TC Kimlik No before providing account information",
    "Agent should provide clear and accurate Turkish bank account balance information in Turkish Lira (TL)",
    "Agent should explain recent Turkish banking transactions in an understandable way"
]
```

**What the LLM Evaluates:**
1. âœ… Did agent verify identity with TC Kimlik No?
2. âœ… Did agent communicate the balance in Turkish Lira?
3. âœ… Did agent explain the transactions clearly?

**The LLM can evaluate this regardless of:**
- Language (Turkish/English/Mixed)
- Phrasing (exact words don't matter)
- Format (numbers, currency symbols, etc.)

---

## Cost Considerations

### **Substring Matching (communicate_info):**
- Cost: $0 (no LLM calls)
- Speed: Instant
- Accuracy: Low (brittle, language-specific)

### **LLM Evaluation (nl_assertions):**
- Cost: ~$0.001-0.01 per evaluation (small)
- Speed: Few seconds per task
- Accuracy: High (semantic understanding)

**Recommendation:** Use LLM evaluation for production/research use cases.

---

## Summary

âœ… **Changed from:** `communicate_info` (substring matching)  
âœ… **Changed to:** `nl_assertions` (LLM-as-a-judge)  
âœ… **Benefit:** Works with Turkish language and semantic understanding  
âœ… **Trade-off:** Small cost increase, much better accuracy  

**Result:** Agent's Turkish responses will now be properly evaluated! ğŸ‡¹ğŸ‡·

---

## Commands to Run

```bash
# Run with NL assertions (now default for banking)
tau2 run --domain banking --task-ids banking_001

# View results
tau2 view
```

The simulation will now properly evaluate Turkish banking conversations!
